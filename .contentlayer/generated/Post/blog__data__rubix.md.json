{
  "category": "data",
  "date": "2015-04-13T00:00:00.000Z",
  "featured": false,
  "subtitle": "A Framework for Improving Data Integration with Linked Data",
  "summary": "RUBIX is a framework that enables business users to semi-automatically combine potentially noisy data residing in heterogeneous silos. Semantically related data is identified and appropriate mappings are suggested to users",
  "tags": [
    "Semantic Web",
    "Schema Matching",
    "Data Integration"
  ],
  "title": "RUBIX",
  "body": {
    "raw": "\n# Introduction\n\nCompanies have traditionally performed business analysis based on transactional data stored in legacy relational databases. The enterprise data available for decision makers was typically relationship management or [enterprise resource planning](http://en.wikipedia.org/wiki/Enterprise_resource_planning 'Enterprise resource planning') data. However, social media feeds, weblogs, sensor data, or data published by governments or international organizations are becoming increasingly available.\n\n> With today's public data sets containing billions of data items, more and more companies are looking to integrate external data with their traditional enterprise data to improve business intelligence analysis. These distributed data sources, however, exhibit heterogeneous data formats and terminologies and may contain noisy data. RUBIX is a novel framework that enables business users to semi-automatically perform [data integration](http://en.wikipedia.org/wiki/Data_integration' Data integration') on potentially noisy tabular data. This framework offers an extension to [Open Refine](http://openrefine.org/) (Formerly [Google Refine](http://code.google.com/p/google-refine/ 'Google Refine')) with novel [schema matching](http://en.wikipedia.org/wiki/Schema_matching 'Schema matching') algorithms leveraging Freebase rich types. First experiments show that using [Linked Data](http://en.wikipedia.org/wiki/Linked_data 'Linked data') to map cell values with instances and column headers with types significantly improves the quality of the matching results and, therefore, should lead to more informed decisions.\n\nThe quality and amount of structured knowledge available make it feasible for companies to mine this massive amount of public data and integrate it into their next-generation enterprise information management systems. Analyzing this new type of data within the context of existing enterprise data should bring them new or more accurate business insights and allow better recognition of sales and market opportunities. These new distributed sources, however, raise tremendous challenges. They have inherently different file formats, access protocols, or query languages. They possess a data model with different ways of representing and storing the data.\n\nData across these sources may be noisy (e.g., duplicate or inconsistent), uncertain, or semantically similar yet different. Therefore, integration and provision of a unified view for these heterogeneous and complex data structures require potent tools to map and organize the data. RUBIX is a framework that enables business users to semi-automatically combine potentially noisy data residing in heterogeneous silos. Semantically related data is identified, and appropriate mappings are suggested to users. On user acceptance, data is aggregated and can be visualized directly or exported to [Business Intelligence](http://en.wikipedia.org/wiki/Business_intelligence' Business intelligence') reporting tools.\n\nThe framework is composed of a set of extensions to Open Refine (now called [Open Refine](http://openrefine.org/)) server and a plug-in to its user interface. Open Refine was selected for its extensibility and good cleansing and transformation capabilities. We first map cell values with instances and column headers with types from popular data sets from the Linked [Open Data](http://en.wikipedia.org/wiki/Open_data 'Open data') Cloud. To perform the matching, we use the Auto Mapping Core (also called AMC ) that combines the results of various similarity algorithms. The novelty of our approach resides in our exploitation of Linked Data to improve the schema-matching process. We developed specific algorithms on rich types from vector algebra and statistics. The AMC generates a list of high-quality mappings from these algorithms allowing better data integration. First experiments show that Linked Data significantly increases the number of mappings suggested to the user. Schemas can also be discovered if column headers need to be defined and can be improved when they are not named or typed correctly. Finally, data reconciliation can be performed regardless of data source languages or ambiguity. All these enhancements allow business users to get more valuable and higher-quality data and, consequently, to make more informed decisions.\n\n# Related Work\n\nWhile schema matching has always been an active research area in data integration, new challenges are faced today by the increasing size, number, and complexity of data sources and their distribution over the network. Data sets are only sometimes correctly typed or labeled, hindering matching. Some work has tried to improve existing data schemas in the past, but literature mainly covers automatic or semi-automatic labeling of anonymous data sets through Web extraction. Examples include automatically labeling news articles with a tree structure analysis or defining heuristics based on distance and alignment of a data value and its label.\n\nThese approaches, however, restricting label candidates to Web content from which the data was extracted, go a step further by launching speculative queries to standard Web search engines to enlarge the set of potential candidate labels. More recently, applies machine learning techniques to respectively annotate table rows as entities, columns as their types, and pairs of columns as relationships, referring to the YAGO ontology. The work presented aims, however, at leveraging such annotations to assist semantic search query construction and not at improving schema matching. With the emergence of the Semantic Web, new work in the area has tried to exploit Linked Data repositories.\n\nThe authors of the present techniques automatically infer a semantic model on tabular data by getting top candidates from Wikitology and classifying them with the Google page ranking algorithm. Since the authors aim to export the resulting table data as Linked Data and not improve schema matching, some columns can be mislabeled, and acronyms and languages need to be better handled. A tagging mechanism adds semantic information to tabular data in the Helix project. A sample of instance values for each column is taken, and a set of tags with scores are gathered from online sources such as Freebase. Tags are then correlated to infer annotations for the column. The mechanism is similar to ours, but the resulting tags for the column are independent of the existing column name, and sampling may not always provide a representative population of the instance values.\n\n# Proposition\n\n[Open Refine](http://openrefine.org/) (formerly Google Refine and Freebase Gridworks) is a tool designed to quickly and efficiently process, clean, and eventually enrich large amounts of data with existing knowledge bases such as Freebase. The tool has, however, some limitations: it was initially designed for data cleansing on only one data set at a time, with no possibility to compose columns from different data sets. Moreover, Open Refine has some strict assumptions over the input of spreadsheets, making it challenging to identify primitive and complex data types. The AMC is a novel framework that supports the construction and execution of new matching components or algorithms. AMC contains several matching components that can be plugged and used, like string matches (Levenshtein, JaroWinkler … etc.), data types matches, and path matches. It also provides a combination and selection algorithms to produce optimized results (weighted average, average, sigmoid … etc.).\n\n## Activity Flow\n\nThe data set to match can be contained in files (e.g., CSV, Excel spreadsheets, etc.) or defined in Open Refine projects. The inputs for the match module are the source and target files and/or projects that contain the data sets.\n\n- These projects are imported into the AMC's internal data structure (called schema).\n- The AMC then uses a set of built-in algorithms to calculate similarities between the source and target schemas on an element basis, i.e., column names in the case of spreadsheets or relational databases.\n- The output is a set of similarities, each containing a triple consisting of source schema element, target element, and similarity between the two.\n- These results are presented to the user in tabular form such that s/he can check, correct, and potentially complete the mappings.\n- Once the user has completed matching columns, the merge information is sent back to Open Refine, which calls the merge module.\n- This module creates a new project, which contains a union of the two projects where the matched columns of the target project are appended to the corresponding source columns.\n- The user can then select the columns that s/he wants to merge and visualize by dragging and dropping the required columns onto the fields that represent the x and y axes.\n- Once the selection has been performed, the aggregation module merges the filtered columns, and the result can be visualized.\n\nAs aggregation operations can quickly become complex, our default aggregation module can be replaced by more advanced analytics on tabular data.\n\n## Schema Matching\n\nSchema matching is typically used in business-to-business integration, metamodel matching, as well as [Extract, Transform, Load (ETL)](http://en.wikipedia.org/wiki/Extract,_transform,_load) processes. For non-IT specialists, the typical way of comparing financial data from two different years or quarters is to copy and paste the data from one Excel spreadsheet into another one, thus creating redundancies and potentially introducing copy-and-paste errors. Schema matching techniques can support this process semi-automatically, i.e., to determine which columns are similar and propose them to the user for integration. This integration can then be done with appropriate business intelligence tools to provide visualizations. One of the problems in performing the integration is the quality of data. The columns may contain data that needs to be fixed or corrected. There may also be no column headers to provide suitable information for matching. Several approaches exploit the similarities of headers or similarities of types of column data. We propose a new approach that exploits semantic-rich typing provided by popular datasets from the Linked Data Cloud.\n\n## Data Reconciliation\n\nReconciliation enables entity resolution, i.e., matching cells with corresponding typed entities in case of tabular data. Open Refine already supports reconciliation with Freebase but requires confirmation from the user. For medium to large data sets, this can be very time-consuming. To reconcile data, we, therefore, first identify the columns that are candidates for reconciliation by skipping the columns containing numerical values or dates. We then use the Freebase search API to query for each cell of the source and target columns the list of typed entity candidates. Results are cached to be retrieved by our similarity algorithms.\n\n## Matching Unnamed and Untyped Columns\n\nThe AMC can combine the results of different matching algorithms. Its default built-in matching algorithms work on column headers, producing an overall similarity score between the compared schema elements. It has been proven that combining different algorithms dramatically increases the quality of matching results. However, when headers are missing or ambiguous, the AMC can only exploit domain intersection and inclusion algorithms based on column data. Therefore, We have implemented three new similarity algorithms that leverage the rich types retrieved from Linked Data to enhance the matching results of unnamed or untyped columns.\n\n## [Cosine Similarity](http://en.wikipedia.org/wiki/Cosine_similarity)\n\nThe first algorithm that we implemented is based on vector algebra. Let $\\mathbf{v}$ be the vector of ranked candidate types returned by Freebase for each cell value of a column. \n\n## [Pearson Product-Moment Correlation Coefficient (PPMCC)](http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient)\n\nThe second algorithm we implemented is PPMCC, a statistical measure of the linear independence between two variables \\\\(\\left(x,y\\right)\\\\). In our method, x is an array that represents the total scores for the source column-rich types, and y is an array that represents the mapped values between the source and the target columns. The values present in x but not in y are represented by zeros.\n\n## [Spearman’s Rank Correlation Coefficient](http://en.wikipedia.org/wiki/Spearman's_rank_correlation_coefficient)\n\nThe last algorithm we implemented to match unnamed and untyped columns is Spearman's rank correlation coefficient. It applies a rank transformation on the input data and computes PPMCC afterward on the ranked data. Our experiments used Natural Ranking with default strategies for handling ties and NaN values. The ranking algorithm is, however, configurable and can be enhanced by using more sophisticated measures.\n\n## Handling Non-String Values\n\nSo far, we have covered several methods to identify the similarity between \"String\" values, but how about other numeral values like dates, money, distance …etc. For this purpose, we have implemented some primary type identifiers that recognize dates, money, numeral values, and numerals used as identifiers. This will help us better match corresponding entries. Adjusting AMC's combination algorithms can be very important at this stage; for example, assigning weights to different matches and tweaking the configuration can result in more accurate results.\n\n# Experiments\n\nWe present in this section the results from experiments we conducted using the methods described above. To appreciate the value of our approach, we have used a real-life scenario that exposes common problems faced by the management in SAP. Our data come from two different SAP systems; the Event Tracker and the Travel Expense Manager. The Event Tracker provides an overview of events (Conferences, Internal events … etc.) that SAP Research employees contribute to or host. The entries in this system contain as much information as necessary to give an overview of the activity like the Activity type and title, travel destination, travel costs divided into several subcategories (conference fees, accommodation, transportation, and others), and duration related information (departure, return dates) … etc. Entries in the Event Tracker are generally entered in batches as employees fill in the planned events they wish to attend or contribute to at the beginning of each year. Afterward, according to their allocated budget, managers can accept or reject these planned events.\nOn the other hand, the Travel Expense Manager contains the actual data for the successfully accepted events. This system is used by employees to enter their actual trip details to claim their expenses. It contains more detailed information and aggregated views of the events, such as the total cost, duration calculated in days, currency exchange rates, and many internal system tags and Identifiers. Matching reports from these two systems is of great benefit to managers to organize and monitor their allocated budget; they mainly want to:\n\n1. Find the number of the actual (accepted plans) compared with the total number of entered events.\n2. Calculate the deviation between each event's estimated and actual cost.\n\nHowever, matching from these two sources can face several difficulties that can be classified into two domains; the first is in global labels (or column headers as we are dealing with Excel-like files). These problems can be summarized in the following:\n\n- **Missing labels**: Importing files into Open Refine with empty headers will assign that column a dummy name by concatenating the word \"column\" with a number starting from 0.\n- **Dummy labels or semantically unrelated names**: This is a common problem, especially from the data coming from the Travel Expense Manager. This can be applied to columns labeled according to the corresponding database table (i.e., lbl_dst to denote destination label). Moreover, column labels do not often convey the semantic type of the underlying data.\n\nThe second domain is at the cell (single entry) level; these problems can be summarized in the:\n\n- Detecting different date formats: We discovered that the date fields from the two systems have different formats. Moreover, the built-in type detection in Open Refine converts the detected date (if found) into another third format.\n- Entries from different people can be made in different languages.\n- Entries in the two systems can be incomplete; the system can shorten an entry automatically; for example, selecting a country in the Travel Expense Manager will result in filling out that country code in the exported report (i.e., France = FR).\n- Inaccurate entries: This is one of the most common problems faced; users in the same field can enter several values corresponding to the same entity. For example, in the destination column, users can enter the country, the airport at the destination, the city, or even the event's exact location (i.e., office location).\nCompleting a Ph.D. can be a hell of a task. It took me lots of time to develop a framework that optimizes how I do research and write and publish my research. This post discusses some of the tools and techniques I used in addition to LaTEX best practices.",
    "code": "var Component=(()=>{var da=Object.create;var S=Object.defineProperty;var la=Object.getOwnPropertyDescriptor;var ma=Object.getOwnPropertyNames;var ua=Object.getPrototypeOf,fa=Object.prototype.hasOwnProperty;var B=(m,a)=>()=>(a||m((a={exports:{}}).exports,a),a.exports),ca=(m,a)=>{for(var p in a)S(m,p,{get:a[p],enumerable:!0})},ye=(m,a,p,w)=>{if(a&&typeof a==\"object\"||typeof a==\"function\")for(let _ of ma(a))!fa.call(m,_)&&_!==p&&S(m,_,{get:()=>a[_],enumerable:!(w=la(a,_))||w.enumerable});return m};var ha=(m,a,p)=>(p=m!=null?da(ua(m)):{},ye(a||!m||!m.__esModule?S(p,\"default\",{value:m,enumerable:!0}):p,m)),ba=m=>ye(S({},\"__esModule\",{value:!0}),m);var Ne=B((ya,ve)=>{ve.exports=React});var De=B(G=>{\"use strict\";(function(){\"use strict\";var m=Ne(),a=Symbol.for(\"react.element\"),p=Symbol.for(\"react.portal\"),w=Symbol.for(\"react.fragment\"),_=Symbol.for(\"react.strict_mode\"),X=Symbol.for(\"react.profiler\"),H=Symbol.for(\"react.provider\"),K=Symbol.for(\"react.context\"),k=Symbol.for(\"react.forward_ref\"),P=Symbol.for(\"react.suspense\"),A=Symbol.for(\"react.suspense_list\"),T=Symbol.for(\"react.memo\"),F=Symbol.for(\"react.lazy\"),Te=Symbol.for(\"react.offscreen\"),J=Symbol.iterator,Ue=\"@@iterator\";function Ee(e){if(e===null||typeof e!=\"object\")return null;var t=J&&e[J]||e[Ue];return typeof t==\"function\"?t:null}var v=m.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;function c(e){{for(var t=arguments.length,r=new Array(t>1?t-1:0),i=1;i<t;i++)r[i-1]=arguments[i];Re(\"error\",e,r)}}function Re(e,t,r){{var i=v.ReactDebugCurrentFrame,d=i.getStackAddendum();d!==\"\"&&(t+=\"%s\",r=r.concat([d]));var l=r.map(function(o){return String(o)});l.unshift(\"Warning: \"+t),Function.prototype.apply.call(console[e],console,l)}}var Ce=!1,Oe=!1,Se=!1,Pe=!1,Ae=!1,Z;Z=Symbol.for(\"react.module.reference\");function Fe(e){return!!(typeof e==\"string\"||typeof e==\"function\"||e===w||e===X||Ae||e===_||e===P||e===A||Pe||e===Te||Ce||Oe||Se||typeof e==\"object\"&&e!==null&&(e.$$typeof===F||e.$$typeof===T||e.$$typeof===H||e.$$typeof===K||e.$$typeof===k||e.$$typeof===Z||e.getModuleId!==void 0))}function Me(e,t,r){var i=e.displayName;if(i)return i;var d=t.displayName||t.name||\"\";return d!==\"\"?r+\"(\"+d+\")\":r}function Q(e){return e.displayName||\"Context\"}function g(e){if(e==null)return null;if(typeof e.tag==\"number\"&&c(\"Received an unexpected object in getComponentNameFromType(). This is likely a bug in React. Please file an issue.\"),typeof e==\"function\")return e.displayName||e.name||null;if(typeof e==\"string\")return e;switch(e){case w:return\"Fragment\";case p:return\"Portal\";case X:return\"Profiler\";case _:return\"StrictMode\";case P:return\"Suspense\";case A:return\"SuspenseList\"}if(typeof e==\"object\")switch(e.$$typeof){case K:var t=e;return Q(t)+\".Consumer\";case H:var r=e;return Q(r._context)+\".Provider\";case k:return Me(e,e.render,\"ForwardRef\");case T:var i=e.displayName||null;return i!==null?i:g(e.type)||\"Memo\";case F:{var d=e,l=d._payload,o=d._init;try{return g(o(l))}catch{return null}}}return null}var y=Object.assign,I=0,ee,ae,ne,te,re,ie,se;function oe(){}oe.__reactDisabledLog=!0;function We(){{if(I===0){ee=console.log,ae=console.info,ne=console.warn,te=console.error,re=console.group,ie=console.groupCollapsed,se=console.groupEnd;var e={configurable:!0,enumerable:!0,value:oe,writable:!0};Object.defineProperties(console,{info:e,log:e,warn:e,error:e,group:e,groupCollapsed:e,groupEnd:e})}I++}}function Le(){{if(I--,I===0){var e={configurable:!0,enumerable:!0,writable:!0};Object.defineProperties(console,{log:y({},e,{value:ee}),info:y({},e,{value:ae}),warn:y({},e,{value:ne}),error:y({},e,{value:te}),group:y({},e,{value:re}),groupCollapsed:y({},e,{value:ie}),groupEnd:y({},e,{value:se})})}I<0&&c(\"disabledDepth fell below zero. This is a bug in React. Please file an issue.\")}}var M=v.ReactCurrentDispatcher,W;function U(e,t,r){{if(W===void 0)try{throw Error()}catch(d){var i=d.stack.trim().match(/\\n( *(at )?)/);W=i&&i[1]||\"\"}return`\n`+W+e}}var L=!1,E;{var qe=typeof WeakMap==\"function\"?WeakMap:Map;E=new qe}function de(e,t){if(!e||L)return\"\";{var r=E.get(e);if(r!==void 0)return r}var i;L=!0;var d=Error.prepareStackTrace;Error.prepareStackTrace=void 0;var l;l=M.current,M.current=null,We();try{if(t){var o=function(){throw Error()};if(Object.defineProperty(o.prototype,\"props\",{set:function(){throw Error()}}),typeof Reflect==\"object\"&&Reflect.construct){try{Reflect.construct(o,[])}catch(x){i=x}Reflect.construct(e,[],o)}else{try{o.call()}catch(x){i=x}e.call(o.prototype)}}else{try{throw Error()}catch(x){i=x}e()}}catch(x){if(x&&i&&typeof x.stack==\"string\"){for(var s=x.stack.split(`\n`),h=i.stack.split(`\n`),u=s.length-1,f=h.length-1;u>=1&&f>=0&&s[u]!==h[f];)f--;for(;u>=1&&f>=0;u--,f--)if(s[u]!==h[f]){if(u!==1||f!==1)do if(u--,f--,f<0||s[u]!==h[f]){var b=`\n`+s[u].replace(\" at new \",\" at \");return e.displayName&&b.includes(\"<anonymous>\")&&(b=b.replace(\"<anonymous>\",e.displayName)),typeof e==\"function\"&&E.set(e,b),b}while(u>=1&&f>=0);break}}}finally{L=!1,M.current=l,Le(),Error.prepareStackTrace=d}var D=e?e.displayName||e.name:\"\",we=D?U(D):\"\";return typeof e==\"function\"&&E.set(e,we),we}function Ye(e,t,r){return de(e,!1)}function $e(e){var t=e.prototype;return!!(t&&t.isReactComponent)}function R(e,t,r){if(e==null)return\"\";if(typeof e==\"function\")return de(e,$e(e));if(typeof e==\"string\")return U(e);switch(e){case P:return U(\"Suspense\");case A:return U(\"SuspenseList\")}if(typeof e==\"object\")switch(e.$$typeof){case k:return Ye(e.render);case T:return R(e.type,t,r);case F:{var i=e,d=i._payload,l=i._init;try{return R(l(d),t,r)}catch{}}}return\"\"}var C=Object.prototype.hasOwnProperty,le={},me=v.ReactDebugCurrentFrame;function O(e){if(e){var t=e._owner,r=R(e.type,e._source,t?t.type:null);me.setExtraStackFrame(r)}else me.setExtraStackFrame(null)}function Ve(e,t,r,i,d){{var l=Function.call.bind(C);for(var o in e)if(l(e,o)){var s=void 0;try{if(typeof e[o]!=\"function\"){var h=Error((i||\"React class\")+\": \"+r+\" type `\"+o+\"` is invalid; it must be a function, usually from the `prop-types` package, but received `\"+typeof e[o]+\"`.This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.\");throw h.name=\"Invariant Violation\",h}s=e[o](t,o,i,r,null,\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\")}catch(u){s=u}s&&!(s instanceof Error)&&(O(d),c(\"%s: type specification of %s `%s` is invalid; the type checker function must return `null` or an `Error` but returned a %s. You may have forgotten to pass an argument to the type checker creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and shape all require an argument).\",i||\"React class\",r,o,typeof s),O(null)),s instanceof Error&&!(s.message in le)&&(le[s.message]=!0,O(d),c(\"Failed %s type: %s\",r,s.message),O(null))}}}var ze=Array.isArray;function q(e){return ze(e)}function Be(e){{var t=typeof Symbol==\"function\"&&Symbol.toStringTag,r=t&&e[Symbol.toStringTag]||e.constructor.name||\"Object\";return r}}function Ge(e){try{return ue(e),!1}catch{return!0}}function ue(e){return\"\"+e}function fe(e){if(Ge(e))return c(\"The provided key is an unsupported type %s. This value must be coerced to a string before before using it here.\",Be(e)),ue(e)}var j=v.ReactCurrentOwner,Xe={key:!0,ref:!0,__self:!0,__source:!0},ce,he,Y;Y={};function He(e){if(C.call(e,\"ref\")){var t=Object.getOwnPropertyDescriptor(e,\"ref\").get;if(t&&t.isReactWarning)return!1}return e.ref!==void 0}function Ke(e){if(C.call(e,\"key\")){var t=Object.getOwnPropertyDescriptor(e,\"key\").get;if(t&&t.isReactWarning)return!1}return e.key!==void 0}function Je(e,t){if(typeof e.ref==\"string\"&&j.current&&t&&j.current.stateNode!==t){var r=g(j.current.type);Y[r]||(c('Component \"%s\" contains the string ref \"%s\". Support for string refs will be removed in a future major release. This case cannot be automatically converted to an arrow function. We ask you to manually fix this case by using useRef() or createRef() instead. Learn more about using refs safely here: https://reactjs.org/link/strict-mode-string-ref',g(j.current.type),e.ref),Y[r]=!0)}}function Ze(e,t){{var r=function(){ce||(ce=!0,c(\"%s: `key` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\",t))};r.isReactWarning=!0,Object.defineProperty(e,\"key\",{get:r,configurable:!0})}}function Qe(e,t){{var r=function(){he||(he=!0,c(\"%s: `ref` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\",t))};r.isReactWarning=!0,Object.defineProperty(e,\"ref\",{get:r,configurable:!0})}}var ea=function(e,t,r,i,d,l,o){var s={$$typeof:a,type:e,key:t,ref:r,props:o,_owner:l};return s._store={},Object.defineProperty(s._store,\"validated\",{configurable:!1,enumerable:!1,writable:!0,value:!1}),Object.defineProperty(s,\"_self\",{configurable:!1,enumerable:!1,writable:!1,value:i}),Object.defineProperty(s,\"_source\",{configurable:!1,enumerable:!1,writable:!1,value:d}),Object.freeze&&(Object.freeze(s.props),Object.freeze(s)),s};function aa(e,t,r,i,d){{var l,o={},s=null,h=null;r!==void 0&&(fe(r),s=\"\"+r),Ke(t)&&(fe(t.key),s=\"\"+t.key),He(t)&&(h=t.ref,Je(t,d));for(l in t)C.call(t,l)&&!Xe.hasOwnProperty(l)&&(o[l]=t[l]);if(e&&e.defaultProps){var u=e.defaultProps;for(l in u)o[l]===void 0&&(o[l]=u[l])}if(s||h){var f=typeof e==\"function\"?e.displayName||e.name||\"Unknown\":e;s&&Ze(o,f),h&&Qe(o,f)}return ea(e,s,h,d,i,j.current,o)}}var $=v.ReactCurrentOwner,be=v.ReactDebugCurrentFrame;function N(e){if(e){var t=e._owner,r=R(e.type,e._source,t?t.type:null);be.setExtraStackFrame(r)}else be.setExtraStackFrame(null)}var V;V=!1;function z(e){return typeof e==\"object\"&&e!==null&&e.$$typeof===a}function pe(){{if($.current){var e=g($.current.type);if(e)return`\n\nCheck the render method of \\``+e+\"`.\"}return\"\"}}function na(e){{if(e!==void 0){var t=e.fileName.replace(/^.*[\\\\\\/]/,\"\"),r=e.lineNumber;return`\n\nCheck your code at `+t+\":\"+r+\".\"}return\"\"}}var ge={};function ta(e){{var t=pe();if(!t){var r=typeof e==\"string\"?e:e.displayName||e.name;r&&(t=`\n\nCheck the top-level render call using <`+r+\">.\")}return t}}function xe(e,t){{if(!e._store||e._store.validated||e.key!=null)return;e._store.validated=!0;var r=ta(t);if(ge[r])return;ge[r]=!0;var i=\"\";e&&e._owner&&e._owner!==$.current&&(i=\" It was passed a child from \"+g(e._owner.type)+\".\"),N(e),c('Each child in a list should have a unique \"key\" prop.%s%s See https://reactjs.org/link/warning-keys for more information.',r,i),N(null)}}function _e(e,t){{if(typeof e!=\"object\")return;if(q(e))for(var r=0;r<e.length;r++){var i=e[r];z(i)&&xe(i,t)}else if(z(e))e._store&&(e._store.validated=!0);else if(e){var d=Ee(e);if(typeof d==\"function\"&&d!==e.entries)for(var l=d.call(e),o;!(o=l.next()).done;)z(o.value)&&xe(o.value,t)}}}function ra(e){{var t=e.type;if(t==null||typeof t==\"string\")return;var r;if(typeof t==\"function\")r=t.propTypes;else if(typeof t==\"object\"&&(t.$$typeof===k||t.$$typeof===T))r=t.propTypes;else return;if(r){var i=g(t);Ve(r,e.props,\"prop\",i,e)}else if(t.PropTypes!==void 0&&!V){V=!0;var d=g(t);c(\"Component %s declared `PropTypes` instead of `propTypes`. Did you misspell the property assignment?\",d||\"Unknown\")}typeof t.getDefaultProps==\"function\"&&!t.getDefaultProps.isReactClassApproved&&c(\"getDefaultProps is only used on classic React.createClass definitions. Use a static property named `defaultProps` instead.\")}}function ia(e){{for(var t=Object.keys(e.props),r=0;r<t.length;r++){var i=t[r];if(i!==\"children\"&&i!==\"key\"){N(e),c(\"Invalid prop `%s` supplied to `React.Fragment`. React.Fragment can only have `key` and `children` props.\",i),N(null);break}}e.ref!==null&&(N(e),c(\"Invalid attribute `ref` supplied to `React.Fragment`.\"),N(null))}}function sa(e,t,r,i,d,l){{var o=Fe(e);if(!o){var s=\"\";(e===void 0||typeof e==\"object\"&&e!==null&&Object.keys(e).length===0)&&(s+=\" You likely forgot to export your component from the file it's defined in, or you might have mixed up default and named imports.\");var h=na(d);h?s+=h:s+=pe();var u;e===null?u=\"null\":q(e)?u=\"array\":e!==void 0&&e.$$typeof===a?(u=\"<\"+(g(e.type)||\"Unknown\")+\" />\",s=\" Did you accidentally export a JSX literal instead of a component?\"):u=typeof e,c(\"React.jsx: type is invalid -- expected a string (for built-in components) or a class/function (for composite components) but got: %s.%s\",u,s)}var f=aa(e,t,r,d,l);if(f==null)return f;if(o){var b=t.children;if(b!==void 0)if(i)if(q(b)){for(var D=0;D<b.length;D++)_e(b[D],e);Object.freeze&&Object.freeze(b)}else c(\"React.jsx: Static children should always be an array. You are likely explicitly calling React.jsxs or React.jsxDEV. Use the Babel transform instead.\");else _e(b,e)}return e===w?ia(f):ra(f),f}}var oa=sa;G.Fragment=w,G.jsxDEV=oa})()});var je=B((Na,Ie)=>{\"use strict\";Ie.exports=De()});var _a={};ca(_a,{default:()=>xa,frontmatter:()=>pa});var n=ha(je()),pa={type:\"Post\",title:\"RUBIX\",tags:[\"Semantic Web\",\"Schema Matching\",\"Data Integration\"],summary:\"RUBIX is a framework that enables business users to semi-automatically combine potentially noisy data residing in heterogeneous silos. Semantically related data is identified and appropriate mappings are suggested to users\",subtitle:\"A Framework for Improving Data Integration with Linked Data\",featured:!1,date:\"2015-04-13\",category:\"data\"};function ke(m){let a=Object.assign({h1:\"h1\",a:\"a\",span:\"span\",p:\"p\",blockquote:\"blockquote\",h2:\"h2\",ul:\"ul\",li:\"li\",math:\"math\",semantics:\"semantics\",mrow:\"mrow\",mi:\"mi\",annotation:\"annotation\",ol:\"ol\",strong:\"strong\"},m.components);return(0,n.jsxDEV)(n.Fragment,{children:[(0,n.jsxDEV)(a.h1,{id:\"introduction\",children:[(0,n.jsxDEV)(a.a,{href:\"#introduction\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsxDEV)(a.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),\"Introduction\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:12,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:[\"Companies have traditionally performed business analysis based on transactional data stored in legacy relational databases. The enterprise data available for decision makers was typically relationship management or \",(0,n.jsxDEV)(a.a,{href:\"http://en.wikipedia.org/wiki/Enterprise_resource_planning\",title:\"Enterprise resource planning\",children:\"enterprise resource planning\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:14,columnNumber:216},this),\" data. However, social media feeds, weblogs, sensor data, or data published by governments or international organizations are becoming increasingly available.\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:14,columnNumber:1},this),(0,n.jsxDEV)(a.blockquote,{children:(0,n.jsxDEV)(a.p,{children:[\"With today's public data sets containing billions of data items, more and more companies are looking to integrate external data with their traditional enterprise data to improve business intelligence analysis. These distributed data sources, however, exhibit heterogeneous data formats and terminologies and may contain noisy data. RUBIX is a novel framework that enables business users to semi-automatically perform [data integration](\",(0,n.jsxDEV)(a.a,{href:\"http://en.wikipedia.org/wiki/Data_integration\",children:\"http://en.wikipedia.org/wiki/Data_integration\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:16,columnNumber:439},this),\"' Data integration') on potentially noisy tabular data. This framework offers an extension to \",(0,n.jsxDEV)(a.a,{href:\"http://openrefine.org/\",children:\"Open Refine\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:16,columnNumber:578},this),\" (Formerly \",(0,n.jsxDEV)(a.a,{href:\"http://code.google.com/p/google-refine/\",title:\"Google Refine\",children:\"Google Refine\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:16,columnNumber:626},this),\") with novel \",(0,n.jsxDEV)(a.a,{href:\"http://en.wikipedia.org/wiki/Schema_matching\",title:\"Schema matching\",children:\"schema matching\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:16,columnNumber:711},this),\" algorithms leveraging Freebase rich types. First experiments show that using \",(0,n.jsxDEV)(a.a,{href:\"http://en.wikipedia.org/wiki/Linked_data\",title:\"Linked data\",children:\"Linked Data\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:16,columnNumber:870},this),\" to map cell values with instances and column headers with types significantly improves the quality of the matching results and, therefore, should lead to more informed decisions.\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:16,columnNumber:3},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:16,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:\"The quality and amount of structured knowledge available make it feasible for companies to mine this massive amount of public data and integrate it into their next-generation enterprise information management systems. Analyzing this new type of data within the context of existing enterprise data should bring them new or more accurate business insights and allow better recognition of sales and market opportunities. These new distributed sources, however, raise tremendous challenges. They have inherently different file formats, access protocols, or query languages. They possess a data model with different ways of representing and storing the data.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:18,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:[\"Data across these sources may be noisy (e.g., duplicate or inconsistent), uncertain, or semantically similar yet different. Therefore, integration and provision of a unified view for these heterogeneous and complex data structures require potent tools to map and organize the data. RUBIX is a framework that enables business users to semi-automatically combine potentially noisy data residing in heterogeneous silos. Semantically related data is identified, and appropriate mappings are suggested to users. On user acceptance, data is aggregated and can be visualized directly or exported to [Business Intelligence](\",(0,n.jsxDEV)(a.a,{href:\"http://en.wikipedia.org/wiki/Business_intelligence\",children:\"http://en.wikipedia.org/wiki/Business_intelligence\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:20,columnNumber:617},this),\"' Business intelligence') reporting tools.\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:20,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:[\"The framework is composed of a set of extensions to Open Refine (now called \",(0,n.jsxDEV)(a.a,{href:\"http://openrefine.org/\",children:\"Open Refine\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:22,columnNumber:77},this),\") server and a plug-in to its user interface. Open Refine was selected for its extensibility and good cleansing and transformation capabilities. We first map cell values with instances and column headers with types from popular data sets from the Linked \",(0,n.jsxDEV)(a.a,{href:\"http://en.wikipedia.org/wiki/Open_data\",title:\"Open data\",children:\"Open Data\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:22,columnNumber:368},this),\" Cloud. To perform the matching, we use the Auto Mapping Core (also called AMC ) that combines the results of various similarity algorithms. The novelty of our approach resides in our exploitation of Linked Data to improve the schema-matching process. We developed specific algorithms on rich types from vector algebra and statistics. The AMC generates a list of high-quality mappings from these algorithms allowing better data integration. First experiments show that Linked Data significantly increases the number of mappings suggested to the user. Schemas can also be discovered if column headers need to be defined and can be improved when they are not named or typed correctly. Finally, data reconciliation can be performed regardless of data source languages or ambiguity. All these enhancements allow business users to get more valuable and higher-quality data and, consequently, to make more informed decisions.\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:22,columnNumber:1},this),(0,n.jsxDEV)(a.h1,{id:\"related-work\",children:[(0,n.jsxDEV)(a.a,{href:\"#related-work\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsxDEV)(a.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),\"Related Work\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:24,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:\"While schema matching has always been an active research area in data integration, new challenges are faced today by the increasing size, number, and complexity of data sources and their distribution over the network. Data sets are only sometimes correctly typed or labeled, hindering matching. Some work has tried to improve existing data schemas in the past, but literature mainly covers automatic or semi-automatic labeling of anonymous data sets through Web extraction. Examples include automatically labeling news articles with a tree structure analysis or defining heuristics based on distance and alignment of a data value and its label.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:26,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:\"These approaches, however, restricting label candidates to Web content from which the data was extracted, go a step further by launching speculative queries to standard Web search engines to enlarge the set of potential candidate labels. More recently, applies machine learning techniques to respectively annotate table rows as entities, columns as their types, and pairs of columns as relationships, referring to the YAGO ontology. The work presented aims, however, at leveraging such annotations to assist semantic search query construction and not at improving schema matching. With the emergence of the Semantic Web, new work in the area has tried to exploit Linked Data repositories.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:28,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:\"The authors of the present techniques automatically infer a semantic model on tabular data by getting top candidates from Wikitology and classifying them with the Google page ranking algorithm. Since the authors aim to export the resulting table data as Linked Data and not improve schema matching, some columns can be mislabeled, and acronyms and languages need to be better handled. A tagging mechanism adds semantic information to tabular data in the Helix project. A sample of instance values for each column is taken, and a set of tags with scores are gathered from online sources such as Freebase. Tags are then correlated to infer annotations for the column. The mechanism is similar to ours, but the resulting tags for the column are independent of the existing column name, and sampling may not always provide a representative population of the instance values.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:30,columnNumber:1},this),(0,n.jsxDEV)(a.h1,{id:\"proposition\",children:[(0,n.jsxDEV)(a.a,{href:\"#proposition\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsxDEV)(a.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),\"Proposition\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:32,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:[(0,n.jsxDEV)(a.a,{href:\"http://openrefine.org/\",children:\"Open Refine\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:34,columnNumber:1},this),\" (formerly Google Refine and Freebase Gridworks) is a tool designed to quickly and efficiently process, clean, and eventually enrich large amounts of data with existing knowledge bases such as Freebase. The tool has, however, some limitations: it was initially designed for data cleansing on only one data set at a time, with no possibility to compose columns from different data sets. Moreover, Open Refine has some strict assumptions over the input of spreadsheets, making it challenging to identify primitive and complex data types. The AMC is a novel framework that supports the construction and execution of new matching components or algorithms. AMC contains several matching components that can be plugged and used, like string matches (Levenshtein, JaroWinkler \\u2026 etc.), data types matches, and path matches. It also provides a combination and selection algorithms to produce optimized results (weighted average, average, sigmoid \\u2026 etc.).\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:34,columnNumber:1},this),(0,n.jsxDEV)(a.h2,{id:\"activity-flow\",children:[(0,n.jsxDEV)(a.a,{href:\"#activity-flow\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsxDEV)(a.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),\"Activity Flow\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:36,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:\"The data set to match can be contained in files (e.g., CSV, Excel spreadsheets, etc.) or defined in Open Refine projects. The inputs for the match module are the source and target files and/or projects that contain the data sets.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:38,columnNumber:1},this),(0,n.jsxDEV)(a.ul,{children:[(0,n.jsxDEV)(a.li,{children:\"These projects are imported into the AMC's internal data structure (called schema).\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:40,columnNumber:1},this),(0,n.jsxDEV)(a.li,{children:\"The AMC then uses a set of built-in algorithms to calculate similarities between the source and target schemas on an element basis, i.e., column names in the case of spreadsheets or relational databases.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:41,columnNumber:1},this),(0,n.jsxDEV)(a.li,{children:\"The output is a set of similarities, each containing a triple consisting of source schema element, target element, and similarity between the two.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:42,columnNumber:1},this),(0,n.jsxDEV)(a.li,{children:\"These results are presented to the user in tabular form such that s/he can check, correct, and potentially complete the mappings.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:43,columnNumber:1},this),(0,n.jsxDEV)(a.li,{children:\"Once the user has completed matching columns, the merge information is sent back to Open Refine, which calls the merge module.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:44,columnNumber:1},this),(0,n.jsxDEV)(a.li,{children:\"This module creates a new project, which contains a union of the two projects where the matched columns of the target project are appended to the corresponding source columns.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:45,columnNumber:1},this),(0,n.jsxDEV)(a.li,{children:\"The user can then select the columns that s/he wants to merge and visualize by dragging and dropping the required columns onto the fields that represent the x and y axes.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:46,columnNumber:1},this),(0,n.jsxDEV)(a.li,{children:\"Once the selection has been performed, the aggregation module merges the filtered columns, and the result can be visualized.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:47,columnNumber:1},this)]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:40,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:\"As aggregation operations can quickly become complex, our default aggregation module can be replaced by more advanced analytics on tabular data.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:49,columnNumber:1},this),(0,n.jsxDEV)(a.h2,{id:\"schema-matching\",children:[(0,n.jsxDEV)(a.a,{href:\"#schema-matching\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsxDEV)(a.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),\"Schema Matching\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:51,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:[\"Schema matching is typically used in business-to-business integration, metamodel matching, as well as \",(0,n.jsxDEV)(a.a,{href:\"http://en.wikipedia.org/wiki/Extract,_transform,_load\",children:\"Extract, Transform, Load (ETL)\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:53,columnNumber:103},this),\" processes. For non-IT specialists, the typical way of comparing financial data from two different years or quarters is to copy and paste the data from one Excel spreadsheet into another one, thus creating redundancies and potentially introducing copy-and-paste errors. Schema matching techniques can support this process semi-automatically, i.e., to determine which columns are similar and propose them to the user for integration. This integration can then be done with appropriate business intelligence tools to provide visualizations. One of the problems in performing the integration is the quality of data. The columns may contain data that needs to be fixed or corrected. There may also be no column headers to provide suitable information for matching. Several approaches exploit the similarities of headers or similarities of types of column data. We propose a new approach that exploits semantic-rich typing provided by popular datasets from the Linked Data Cloud.\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:53,columnNumber:1},this),(0,n.jsxDEV)(a.h2,{id:\"data-reconciliation\",children:[(0,n.jsxDEV)(a.a,{href:\"#data-reconciliation\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsxDEV)(a.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),\"Data Reconciliation\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:55,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:\"Reconciliation enables entity resolution, i.e., matching cells with corresponding typed entities in case of tabular data. Open Refine already supports reconciliation with Freebase but requires confirmation from the user. For medium to large data sets, this can be very time-consuming. To reconcile data, we, therefore, first identify the columns that are candidates for reconciliation by skipping the columns containing numerical values or dates. We then use the Freebase search API to query for each cell of the source and target columns the list of typed entity candidates. Results are cached to be retrieved by our similarity algorithms.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:57,columnNumber:1},this),(0,n.jsxDEV)(a.h2,{id:\"matching-unnamed-and-untyped-columns\",children:[(0,n.jsxDEV)(a.a,{href:\"#matching-unnamed-and-untyped-columns\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsxDEV)(a.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),\"Matching Unnamed and Untyped Columns\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:59,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:\"The AMC can combine the results of different matching algorithms. Its default built-in matching algorithms work on column headers, producing an overall similarity score between the compared schema elements. It has been proven that combining different algorithms dramatically increases the quality of matching results. However, when headers are missing or ambiguous, the AMC can only exploit domain intersection and inclusion algorithms based on column data. Therefore, We have implemented three new similarity algorithms that leverage the rich types retrieved from Linked Data to enhance the matching results of unnamed or untyped columns.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:61,columnNumber:1},this),(0,n.jsxDEV)(a.h2,{id:\"cosine-similarity\",children:[(0,n.jsxDEV)(a.a,{href:\"#cosine-similarity\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsxDEV)(a.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),(0,n.jsxDEV)(a.a,{href:\"http://en.wikipedia.org/wiki/Cosine_similarity\",children:\"Cosine Similarity\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:63,columnNumber:4},this)]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:63,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:[\"The first algorithm that we implemented is based on vector algebra. Let \",(0,n.jsxDEV)(a.span,{className:\"math math-inline\",children:(0,n.jsxDEV)(a.span,{className:\"katex\",children:[(0,n.jsxDEV)(a.span,{className:\"katex-mathml\",children:(0,n.jsxDEV)(a.math,{xmlns:\"http://www.w3.org/1998/Math/MathML\",children:(0,n.jsxDEV)(a.semantics,{children:[(0,n.jsxDEV)(a.mrow,{children:(0,n.jsxDEV)(a.mi,{mathvariant:\"bold\",children:\"v\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),(0,n.jsxDEV)(a.annotation,{encoding:\"application/x-tex\",children:\"\\\\mathbf{v}\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),(0,n.jsxDEV)(a.span,{className:\"katex-html\",\"aria-hidden\":\"true\",children:(0,n.jsxDEV)(a.span,{className:\"base\",children:[(0,n.jsxDEV)(a.span,{className:\"strut\",style:{height:\".4444em\"}},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),(0,n.jsxDEV)(a.span,{className:\"mathbf mord\",style:{marginRight:\".01597em\"},children:\"v\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:65,columnNumber:73},this),\" be the vector of ranked candidate types returned by Freebase for each cell value of a column.\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:65,columnNumber:1},this),(0,n.jsxDEV)(a.h2,{id:\"pearson-product-moment-correlation-coefficient-ppmcc\",children:[(0,n.jsxDEV)(a.a,{href:\"#pearson-product-moment-correlation-coefficient-ppmcc\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsxDEV)(a.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),(0,n.jsxDEV)(a.a,{href:\"http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient\",children:\"Pearson Product-Moment Correlation Coefficient (PPMCC)\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:67,columnNumber:4},this)]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:67,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:\"The second algorithm we implemented is PPMCC, a statistical measure of the linear independence between two variables \\\\(\\\\left(x,y\\\\right)\\\\). In our method, x is an array that represents the total scores for the source column-rich types, and y is an array that represents the mapped values between the source and the target columns. The values present in x but not in y are represented by zeros.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:69,columnNumber:1},this),(0,n.jsxDEV)(a.h2,{id:\"spearmans-rank-correlation-coefficient\",children:[(0,n.jsxDEV)(a.a,{href:\"#spearmans-rank-correlation-coefficient\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsxDEV)(a.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),(0,n.jsxDEV)(a.a,{href:\"http://en.wikipedia.org/wiki/Spearman's_rank_correlation_coefficient\",children:\"Spearman\\u2019s Rank Correlation Coefficient\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:71,columnNumber:4},this)]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:71,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:\"The last algorithm we implemented to match unnamed and untyped columns is Spearman's rank correlation coefficient. It applies a rank transformation on the input data and computes PPMCC afterward on the ranked data. Our experiments used Natural Ranking with default strategies for handling ties and NaN values. The ranking algorithm is, however, configurable and can be enhanced by using more sophisticated measures.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:73,columnNumber:1},this),(0,n.jsxDEV)(a.h2,{id:\"handling-non-string-values\",children:[(0,n.jsxDEV)(a.a,{href:\"#handling-non-string-values\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsxDEV)(a.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),\"Handling Non-String Values\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:75,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:`So far, we have covered several methods to identify the similarity between \"String\" values, but how about other numeral values like dates, money, distance \\u2026etc. For this purpose, we have implemented some primary type identifiers that recognize dates, money, numeral values, and numerals used as identifiers. This will help us better match corresponding entries. Adjusting AMC's combination algorithms can be very important at this stage; for example, assigning weights to different matches and tweaking the configuration can result in more accurate results.`},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:77,columnNumber:1},this),(0,n.jsxDEV)(a.h1,{id:\"experiments\",children:[(0,n.jsxDEV)(a.a,{href:\"#experiments\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsxDEV)(a.span,{className:\"icon icon-link\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this),\"Experiments\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:79,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:\"We present in this section the results from experiments we conducted using the methods described above. To appreciate the value of our approach, we have used a real-life scenario that exposes common problems faced by the management in SAP. Our data come from two different SAP systems; the Event Tracker and the Travel Expense Manager. The Event Tracker provides an overview of events (Conferences, Internal events \\u2026 etc.) that SAP Research employees contribute to or host. The entries in this system contain as much information as necessary to give an overview of the activity like the Activity type and title, travel destination, travel costs divided into several subcategories (conference fees, accommodation, transportation, and others), and duration related information (departure, return dates) \\u2026 etc. Entries in the Event Tracker are generally entered in batches as employees fill in the planned events they wish to attend or contribute to at the beginning of each year. Afterward, according to their allocated budget, managers can accept or reject these planned events. On the other hand, the Travel Expense Manager contains the actual data for the successfully accepted events. This system is used by employees to enter their actual trip details to claim their expenses. It contains more detailed information and aggregated views of the events, such as the total cost, duration calculated in days, currency exchange rates, and many internal system tags and Identifiers. Matching reports from these two systems is of great benefit to managers to organize and monitor their allocated budget; they mainly want to:\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:81,columnNumber:1},this),(0,n.jsxDEV)(a.ol,{children:[(0,n.jsxDEV)(a.li,{children:\"Find the number of the actual (accepted plans) compared with the total number of entered events.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:84,columnNumber:1},this),(0,n.jsxDEV)(a.li,{children:\"Calculate the deviation between each event's estimated and actual cost.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:85,columnNumber:1},this)]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:84,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:\"However, matching from these two sources can face several difficulties that can be classified into two domains; the first is in global labels (or column headers as we are dealing with Excel-like files). These problems can be summarized in the following:\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:87,columnNumber:1},this),(0,n.jsxDEV)(a.ul,{children:[(0,n.jsxDEV)(a.li,{children:[(0,n.jsxDEV)(a.strong,{children:\"Missing labels\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:89,columnNumber:3},this),': Importing files into Open Refine with empty headers will assign that column a dummy name by concatenating the word \"column\" with a number starting from 0.']},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:89,columnNumber:1},this),(0,n.jsxDEV)(a.li,{children:[(0,n.jsxDEV)(a.strong,{children:\"Dummy labels or semantically unrelated names\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:90,columnNumber:3},this),\": This is a common problem, especially from the data coming from the Travel Expense Manager. This can be applied to columns labeled according to the corresponding database table (i.e., lbl_dst to denote destination label). Moreover, column labels do not often convey the semantic type of the underlying data.\"]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:90,columnNumber:1},this)]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:89,columnNumber:1},this),(0,n.jsxDEV)(a.p,{children:\"The second domain is at the cell (single entry) level; these problems can be summarized in the:\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:92,columnNumber:1},this),(0,n.jsxDEV)(a.ul,{children:[(0,n.jsxDEV)(a.li,{children:\"Detecting different date formats: We discovered that the date fields from the two systems have different formats. Moreover, the built-in type detection in Open Refine converts the detected date (if found) into another third format.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:94,columnNumber:1},this),(0,n.jsxDEV)(a.li,{children:\"Entries from different people can be made in different languages.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:95,columnNumber:1},this),(0,n.jsxDEV)(a.li,{children:\"Entries in the two systems can be incomplete; the system can shorten an entry automatically; for example, selecting a country in the Travel Expense Manager will result in filling out that country code in the exported report (i.e., France = FR).\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:96,columnNumber:1},this),(0,n.jsxDEV)(a.li,{children:\"Inaccurate entries: This is one of the most common problems faced; users in the same field can enter several values corresponding to the same entity. For example, in the destination column, users can enter the country, the airport at the destination, the city, or even the event's exact location (i.e., office location). Completing a Ph.D. can be a hell of a task. It took me lots of time to develop a framework that optimizes how I do research and write and publish my research. This post discusses some of the tools and techniques I used in addition to LaTEX best practices.\"},void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:97,columnNumber:1},this)]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:94,columnNumber:1},this)]},void 0,!0,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\",lineNumber:1,columnNumber:1},this)}function ga(m={}){let{wrapper:a}=m.components||{};return a?(0,n.jsxDEV)(a,Object.assign({},m,{children:(0,n.jsxDEV)(ke,m,void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this)}),void 0,!1,{fileName:\"/Users/ahmadassaf/Downloads/Inbox/tailwind-nextjs-starter-blog/_mdx_bundler_entry_point-e8d51322-6b63-401d-b92a-3815774f3852.mdx\"},this):ke(m)}var xa=ga;return ba(_a);})();\n/*! Bundled license information:\n\nreact/cjs/react-jsx-dev-runtime.development.js:\n  (**\n   * @license React\n   * react-jsx-dev-runtime.development.js\n   *\n   * Copyright (c) Facebook, Inc. and its affiliates.\n   *\n   * This source code is licensed under the MIT license found in the\n   * LICENSE file in the root directory of this source tree.\n   *)\n*/\n;return Component;"
  },
  "_id": "blog/data/rubix.md",
  "_raw": {
    "sourceFilePath": "blog/data/rubix.md",
    "sourceFileName": "rubix.md",
    "sourceFileDir": "blog/data",
    "contentType": "markdown",
    "flattenedPath": "blog/data/rubix"
  },
  "type": "Post",
  "filePath": "blog/data/rubix.md",
  "path": "blog/data/rubix",
  "readingTime": {
    "text": "13 min read",
    "minutes": 12.805,
    "time": 768300,
    "words": 2561
  },
  "slug": "data/rubix",
  "toc": [
    {
      "value": "Introduction",
      "url": "#introduction",
      "depth": 1
    },
    {
      "value": "Related Work",
      "url": "#related-work",
      "depth": 1
    },
    {
      "value": "Proposition",
      "url": "#proposition",
      "depth": 1
    },
    {
      "value": "Activity Flow",
      "url": "#activity-flow",
      "depth": 2
    },
    {
      "value": "Schema Matching",
      "url": "#schema-matching",
      "depth": 2
    },
    {
      "value": "Data Reconciliation",
      "url": "#data-reconciliation",
      "depth": 2
    },
    {
      "value": "Matching Unnamed and Untyped Columns",
      "url": "#matching-unnamed-and-untyped-columns",
      "depth": 2
    },
    {
      "value": "Cosine Similarity",
      "url": "#cosine-similarity",
      "depth": 2
    },
    {
      "value": "Pearson Product-Moment Correlation Coefficient (PPMCC)",
      "url": "#pearson-product-moment-correlation-coefficient-ppmcc",
      "depth": 2
    },
    {
      "value": "Spearman’s Rank Correlation Coefficient",
      "url": "#spearmans-rank-correlation-coefficient",
      "depth": 2
    },
    {
      "value": "Handling Non-String Values",
      "url": "#handling-non-string-values",
      "depth": 2
    },
    {
      "value": "Experiments",
      "url": "#experiments",
      "depth": 1
    }
  ],
  "structuredData": {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "dateModified": "2015-04-13T00:00:00.000Z",
    "datePublished": "2015-04-13T00:00:00.000Z",
    "description": "RUBIX is a framework that enables business users to semi-automatically combine potentially noisy data residing in heterogeneous silos. Semantically related data is identified and appropriate mappings are suggested to users",
    "headline": "RUBIX",
    "image": "/static/images/twitter-card.png",
    "url": "https://assaf.website/blog/data/rubix"
  }
}